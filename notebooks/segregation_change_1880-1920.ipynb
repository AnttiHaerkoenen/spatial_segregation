{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%% setup\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from typing import Callable\n",
    "import warnings\n",
    "\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "from shapely.geometry import Point\n",
    "from segregation.singlegroup import Dissim, MinMax\n",
    "import rasterio as rio\n",
    "from scipy.spatial.distance import cdist\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "data_dir = Path('../data')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%% Surface-based dissimilarity S\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_xy(\n",
    "        geodf: gpd.GeoDataFrame,\n",
    "        geometry_col: str = None,\n",
    ") -> gpd.GeoDataFrame:\n",
    "\n",
    "    if not geometry_col:\n",
    "        geometry_col = geodf.geometry.name\n",
    "\n",
    "    if geodf[geometry_col].geom_type[0] == 'Point':\n",
    "        geodf['x'] = geodf[geometry_col].apply(lambda geom: geom.x)\n",
    "        geodf['y'] = geodf[geometry_col].apply(lambda geom: geom.y)\n",
    "    else:\n",
    "        geodf['x'] = geodf[geometry_col].apply(lambda geom: tuple(geom.exterior.coords.xy[0]))\n",
    "        geodf['y'] = geodf[geometry_col].apply(lambda geom: tuple(geom.exterior.coords.xy[1]))\n",
    "    return geodf\n",
    "\n",
    "\n",
    "def kernel_density_surface(\n",
    "        data: gpd.GeoDataFrame,\n",
    "        group: str,\n",
    "        bandwidth,\n",
    "        cell_size,\n",
    "        kernel_function: Callable,\n",
    "):\n",
    "    pop = get_xy(data)\n",
    "    pad = bandwidth * 2\n",
    "\n",
    "    minx, miny, maxx, maxy = pop.geometry.total_bounds\n",
    "\n",
    "    minx -= pad\n",
    "    miny -= pad\n",
    "    maxx += pad\n",
    "    maxy += pad\n",
    "\n",
    "    x = np.arange(minx, maxx, cell_size)\n",
    "    y = np.arange(miny, maxy, cell_size)\n",
    "\n",
    "    X, Y = np.meshgrid(x, y)\n",
    "\n",
    "    xy = np.vstack([Y.ravel(), X.ravel()]).T\n",
    "\n",
    "    U = cdist(xy, pop[['y', 'x']].values, metric='euclidean')\n",
    "    W = kernel_function(U, bandwidth=bandwidth)\n",
    "\n",
    "    density = (W * pop[group].values).sum(axis=1).reshape(X.shape)\n",
    "\n",
    "    geotiff_meta = {\n",
    "        'driver': 'GTiff',\n",
    "        'count': 1,\n",
    "        'dtype': density.dtype,\n",
    "        'width': density.shape[1],\n",
    "        'height': density.shape[0],\n",
    "        'crs': data.crs,\n",
    "        'transform': rio.transform.from_bounds(\n",
    "            west=minx,\n",
    "            east=maxx,\n",
    "            north=maxy,\n",
    "            south=miny,\n",
    "            width=len(x),\n",
    "            height=len(y),\n",
    "        )\n",
    "    }\n",
    "\n",
    "    return density[::-1, ], geotiff_meta\n",
    "\n",
    "\n",
    "def get_S(\n",
    "        data,\n",
    "        bandwidth,\n",
    "        cell_size,\n",
    "        kernel_function,\n",
    "):\n",
    "    if data.empty:\n",
    "        return None\n",
    "\n",
    "    density_total, _ = kernel_density_surface(\n",
    "        data,\n",
    "        group='total',\n",
    "        bandwidth=bandwidth,\n",
    "        cell_size=cell_size,\n",
    "        kernel_function=kernel_function,\n",
    "    )\n",
    "    density_orthodox, _ = kernel_density_surface(\n",
    "        data,\n",
    "        group='orthodox',\n",
    "        bandwidth=bandwidth,\n",
    "        cell_size=cell_size,\n",
    "        kernel_function=kernel_function,\n",
    "    )\n",
    "\n",
    "    density = pd.DataFrame({\n",
    "            'orthodox': density_orthodox.flatten(),\n",
    "            'total': density_total.flatten(),\n",
    "         })\n",
    "    S = MinMax(density, 'orthodox', 'total')\n",
    "\n",
    "    return S\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%% Data handling\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def remove_institutions(\n",
    "        pop_data: pd.DataFrame,\n",
    "        institutions: pd.DataFrame,\n",
    "        year,\n",
    "):\n",
    "    institutions = institutions.set_index(['district', 'plot_number'])\n",
    "    institutions = institutions.loc[institutions.year == year]\n",
    "\n",
    "    for idx in institutions.index:\n",
    "        pop_data = pop_data.drop(index=idx, errors='ignore')\n",
    "\n",
    "    return pop_data\n",
    "\n",
    "\n",
    "def prepare_pop_data(\n",
    "        population_data: pd.DataFrame,\n",
    "        num_cols=None,\n",
    ") -> pd.DataFrame:\n",
    "\n",
    "    pop_frame = population_data.fillna(value=0)\n",
    "\n",
    "    if not num_cols:\n",
    "        num_cols = [\n",
    "            'total_men',\n",
    "            'total_women',\n",
    "            'orthodox',\n",
    "            'other_christian',\n",
    "            'other_religion',\n",
    "        ]\n",
    "\n",
    "    pop_frame.loc[:, num_cols] = pop_frame.loc[:, num_cols].astype(int)\n",
    "\n",
    "    pop_frame['lutheran'] = pop_frame['total_men total_women'.split()].sum(axis=1) \\\n",
    "                            - pop_frame['other_christian orthodox other_religion'.split()].sum(axis=1)\n",
    "\n",
    "    pop_frame['total'] = pop_frame['other_christian orthodox other_religion lutheran'.split()].sum(axis=1)\n",
    "\n",
    "    return pop_frame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%% Split plots\n"
    }
   },
   "outputs": [],
   "source": [
    "def split_plots(\n",
    "        geodataframe: gpd.GeoDataFrame,\n",
    "        target_col: str,\n",
    "        separator: str = ',',\n",
    ") -> gpd.GeoDataFrame:\n",
    "\n",
    "    new_geodataframe = gpd.GeoDataFrame(columns=geodataframe.columns)\n",
    "\n",
    "    for _, row in geodataframe.iterrows():\n",
    "        plots = str(row[target_col]).split(separator)\n",
    "\n",
    "        if len(plots) < 2:\n",
    "            new_geodataframe = new_geodataframe.append(row)\n",
    "            continue\n",
    "\n",
    "        for plot in plots:\n",
    "            new_row = row\n",
    "            new_row[target_col] = plot\n",
    "            new_geodataframe = new_geodataframe.append(new_row)\n",
    "\n",
    "    assert len(new_geodataframe.index) == len(list(pd.core.common.flatten(\n",
    "        [\n",
    "            str(w).split(separator)\n",
    "            for w\n",
    "            in geodataframe[target_col]\n",
    "        ]))), 'splitting failed'\n",
    "\n",
    "    return new_geodataframe.reindex()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%% kernel function\n"
    }
   },
   "outputs": [],
   "source": [
    "def quartic_kernel(u, bandwidth):\n",
    "    return np.where(\n",
    "            np.abs(u) <= bandwidth,\n",
    "            3 / (np.pi * bandwidth * bandwidth) * (1 - (u / bandwidth) ** 2) ** 2,\n",
    "            0\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%% main\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "district_codes = pd.read_csv(data_dir / 'district_codes_1878.csv')\n",
    "district_codes = {k: v for k, v in district_codes.itertuples(index=False)}\n",
    "institutions = pd.read_csv(data_dir / 'institutions.csv', dtype={'district': str, 'plot_number': str})\n",
    "\n",
    "location_data = gpd.read_file(data_dir / 'raw' / 'plots_1878.shp').to_crs(epsg=3067)\n",
    "location_data = split_plots(location_data, target_col='NUMBER')\n",
    "location_data['district'] = [district_codes[int(d)] for d in location_data['DISTRICT']]\n",
    "location_data['plot_number'] = [str(i) for i in location_data['NUMBER']]\n",
    "location_data = location_data.set_index(['district', 'plot_number'])\n",
    "city = gpd.read_file(data_dir / 'raw' / 'city_1846.shp').to_crs(epsg=3067)\n",
    "location_data = location_data.loc[~location_data.geometry.within(city.geometry[0]).index.duplicated()]\n",
    "location_data = location_data.loc[location_data.geometry.within(city.geometry[0])]\n",
    "\n",
    "results = {}\n",
    "bws = 100, 150, 200, 250, 300, 400, 500\n",
    "\n",
    "for year in range(1880, 1921, 5):\n",
    "    s_ = []\n",
    "\n",
    "    for bw in bws:\n",
    "        population_data = pd.read_csv(\n",
    "            data_dir / 'interim' / f'pop_by_page_{year}.csv',\n",
    "            index_col=0,\n",
    "            dtype={'district': str, 'representative_plot': str, 'page_number': str},\n",
    "        ).pipe(prepare_pop_data)\n",
    "        population_data.rename({'representative_plot': 'plot_number'}, axis=1, inplace=True)\n",
    "        population_data = population_data.set_index(['district', 'plot_number'], drop=True)\n",
    "\n",
    "        population_data = population_data.pipe(remove_institutions, institutions, year)\n",
    "\n",
    "        page_location_data = location_data.join(population_data, on=['district', 'plot_number'])\n",
    "        page_location_data.dropna(axis=0, inplace=True)\n",
    "\n",
    "        for group in 'orthodox', 'lutheran', 'total':\n",
    "            density, raster_args = kernel_density_surface(\n",
    "                page_location_data,\n",
    "                group=group,\n",
    "                bandwidth=bw,\n",
    "                cell_size=25,\n",
    "                kernel_function=quartic_kernel,\n",
    "            )\n",
    "            density = density * 10_000\n",
    "\n",
    "            file = f\"../data/processed/{group}_density_{year}_{bw}_m.tif\"\n",
    "\n",
    "            with rio.open(file, 'w', **raster_args) as rfile:\n",
    "                rfile.write(density, 1)\n",
    "\n",
    "        S = get_S(\n",
    "            data=page_location_data,\n",
    "            bandwidth=bw,\n",
    "            cell_size=25,\n",
    "            kernel_function=quartic_kernel,\n",
    "        )\n",
    "\n",
    "        s_.append(S.statistic)\n",
    "\n",
    "    results[year] = s_\n",
    "\n",
    "results = pd.DataFrame.from_dict(\n",
    "    results,\n",
    "    orient='index',\n",
    "    columns=bws,\n",
    ")\n",
    "print(results)\n",
    "results.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%% aspatial segregation\n"
    }
   },
   "outputs": [],
   "source": [
    "districts_in_city = [\n",
    "    'Valli',\n",
    "    'Salakkalahti',\n",
    "    'Repola',\n",
    "    'Anina',\n",
    "    'Papula',\n",
    "    'P_Annan_kruunu',\n",
    "    'Hiekka',\n",
    "    'Pantsarlahti',\n",
    "    'Viipurin_esikaupunki',\n",
    "    'Paulovski',\n",
    "    'Havi',\n",
    "    'Saunalahti',\n",
    "    'Pietarin_esikaupunki',\n",
    "]\n",
    "\n",
    "results_D = {}\n",
    "\n",
    "for year in range(1880, 1921, 5):\n",
    "    population_data = pd.read_csv(\n",
    "            data_dir / 'interim' / f'pop_by_page_{year}.csv',\n",
    "            index_col=0,\n",
    "            dtype={'district': str, 'representative_plot': str, 'page_number': str},\n",
    "        ).pipe(prepare_pop_data)\n",
    "    population_data = population_data[population_data.district.isin(districts_in_city)]\n",
    "    population_data = population_data.loc[:, ['district', 'lutheran', 'orthodox', 'total']].groupby('district').sum()\n",
    "    totals = pd.Series(population_data.sum(axis=0), name='totals')\n",
    "    population_data = population_data.append(totals)\n",
    "\n",
    "    D = Dissim(\n",
    "        population_data,\n",
    "        group_pop_var='orthodox',\n",
    "        total_pop_var='total',\n",
    "    )\n",
    "    results_D[year] = D.statistic\n",
    "\n",
    "    print(f'    {year}:')\n",
    "    print(population_data)\n",
    "    print()\n",
    "\n",
    "results['D'] = pd.Series(results_D)\n",
    "print(results)\n",
    "fig, *axes = results.plot(\n",
    "    figsize=(5, 10),\n",
    "    subplots=True,\n",
    "    grid=True,\n",
    ")\n",
    "for ax in axes:\n",
    "    ticks = np.arange(0, 1, 0.05)\n",
    "    ax.set_yticks(ticks)\n",
    "    ax.autoscale_view()\n",
    "plt.savefig('../figures/S_and_D.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Model:\n",
    "\n",
    "$ o_t = y_t - m_t $\n",
    "\n",
    "$ m_t \\sim Poisson(30) $\n",
    "\n",
    "$ y_t = \\theta y_{t-1} + \\epsilon_t $\n",
    "\n",
    "$ \\epsilon_t \\sim N(0, 20^2) $\n",
    "\n",
    "$ \\theta_t \\sim N(0, 0.1^2) $"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}