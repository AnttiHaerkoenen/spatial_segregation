{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% setup\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from typing import Callable\n",
    "import warnings\n",
    "\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "from shapely.geometry import Point\n",
    "from segregation.aspatial import MinMax, Dissim\n",
    "import rasterio as rio\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "\n",
    "data_dir = Path('../data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "outputs": [],
   "source": [
    "def get_xy(\n",
    "        geodf: gpd.GeoDataFrame,\n",
    "        geometry_col: str = None,\n",
    ") -> gpd.GeoDataFrame:\n",
    "\n",
    "    if not geometry_col:\n",
    "        geometry_col = geodf.geometry.name\n",
    "\n",
    "    if geodf[geometry_col].geom_type[0] == 'Point':\n",
    "        geodf['x'] = geodf[geometry_col].apply(lambda geom: geom.x)\n",
    "        geodf['y'] = geodf[geometry_col].apply(lambda geom: geom.y)\n",
    "    else:\n",
    "        geodf['x'] = geodf[geometry_col].apply(lambda geom: tuple(geom.exterior.coords.xy[0]))\n",
    "        geodf['y'] = geodf[geometry_col].apply(lambda geom: tuple(geom.exterior.coords.xy[1]))\n",
    "    return geodf\n",
    "\n",
    "\n",
    "def kernel_density_surface(\n",
    "        data: gpd.GeoDataFrame,\n",
    "        group: str,\n",
    "        bandwidth,\n",
    "        cell_size,\n",
    "        kernel_function: Callable,\n",
    "):\n",
    "    pop = get_xy(data)\n",
    "    pad = bandwidth * 2\n",
    "\n",
    "    minx, miny, maxx, maxy = pop.geometry.total_bounds\n",
    "\n",
    "    minx -= pad\n",
    "    miny -= pad\n",
    "    maxx += pad\n",
    "    maxy += pad\n",
    "\n",
    "    x = np.arange(minx, maxx, cell_size)\n",
    "    y = np.arange(miny, maxy, cell_size)\n",
    "\n",
    "    X, Y = np.meshgrid(x, y)\n",
    "\n",
    "    xy = np.vstack([Y.ravel(), X.ravel()]).T\n",
    "\n",
    "    U = cdist(xy, pop[['y', 'x']].values, metric='euclidean')\n",
    "    W = kernel_function(U, bandwidth=bandwidth)\n",
    "\n",
    "    density = (W * pop[group].values).sum(axis=1).reshape(X.shape)\n",
    "\n",
    "    geotiff_meta = {\n",
    "        'driver': 'GTiff',\n",
    "        'count': 1,\n",
    "        'dtype': 'float64',\n",
    "        'width': len(x),\n",
    "        'height': len(y),\n",
    "        'crs': data.crs,\n",
    "        'transform': rio.transform.from_bounds(\n",
    "            west=minx,\n",
    "            east=maxx,\n",
    "            north=maxy,\n",
    "            south=miny,\n",
    "            width=len(x),\n",
    "            height=len(y),\n",
    "        )\n",
    "    }\n",
    "\n",
    "    return density[::-1, ], geotiff_meta\n",
    "\n",
    "\n",
    "def get_S(\n",
    "        data,\n",
    "        bandwidth,\n",
    "        cell_size,\n",
    "        kernel_function,\n",
    "):\n",
    "    if data.empty:\n",
    "        return None\n",
    "\n",
    "    density_total, _ = kernel_density_surface(\n",
    "        data,\n",
    "        group='total',\n",
    "        bandwidth=bandwidth,\n",
    "        cell_size=cell_size,\n",
    "        kernel_function=kernel_function,\n",
    "    )\n",
    "    density_orthodox, _ = kernel_density_surface(\n",
    "        data,\n",
    "        group='orthodox',\n",
    "        bandwidth=bandwidth,\n",
    "        cell_size=cell_size,\n",
    "        kernel_function=kernel_function,\n",
    "    )\n",
    "\n",
    "    density = pd.DataFrame({\n",
    "            'orthodox': density_orthodox.flatten(),\n",
    "            'total': density_total.flatten(),\n",
    "         })\n",
    "    S = MinMax(density, 'orthodox', 'total')\n",
    "\n",
    "    return S\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Surface-based dissimilarity S\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "outputs": [],
   "source": [
    "\n",
    "def remove_institutions(\n",
    "        pop_data: pd.DataFrame,\n",
    "        institutions: pd.DataFrame,\n",
    "        year,\n",
    "):\n",
    "    institutions = institutions.set_index(['district', 'plot_number'])\n",
    "    institutions = institutions.loc[institutions.year == year]\n",
    "\n",
    "    for idx in institutions.index:\n",
    "        pop_data = pop_data.drop(index=idx, errors='ignore')\n",
    "\n",
    "    return pop_data\n",
    "\n",
    "\n",
    "def prepare_pop_data(\n",
    "        population_data: pd.DataFrame,\n",
    "        num_cols=None,\n",
    ") -> pd.DataFrame:\n",
    "\n",
    "    pop_frame = population_data.fillna(value=0)\n",
    "\n",
    "    if not num_cols:\n",
    "        num_cols = [\n",
    "            'total_men',\n",
    "            'total_women',\n",
    "            'orthodox',\n",
    "            'other_christian',\n",
    "            'other_religion',\n",
    "        ]\n",
    "\n",
    "    pop_frame.loc[:, num_cols] = pop_frame.loc[:, num_cols].astype(int)\n",
    "\n",
    "    pop_frame['lutheran'] = pop_frame['total_men total_women'.split()].sum(axis=1) \\\n",
    "                            - pop_frame['other_christian orthodox other_religion'.split()].sum(axis=1)\n",
    "\n",
    "    pop_frame['total'] = pop_frame['other_christian orthodox other_religion lutheran'.split()].sum(axis=1)\n",
    "\n",
    "    return pop_frame"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Data handling\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "outputs": [],
   "source": [
    "def split_plots(\n",
    "        geodataframe: gpd.GeoDataFrame,\n",
    "        target_col: str,\n",
    "        separator: str = ',',\n",
    ") -> gpd.GeoDataFrame:\n",
    "\n",
    "    new_geodataframe = gpd.GeoDataFrame(columns=geodataframe.columns)\n",
    "\n",
    "    for _, row in geodataframe.iterrows():\n",
    "        plots = str(row[target_col]).split(separator)\n",
    "\n",
    "        if len(plots) < 2:\n",
    "            new_geodataframe = new_geodataframe.append(row)\n",
    "            continue\n",
    "\n",
    "        for plot in plots:\n",
    "            new_row = row\n",
    "            new_row[target_col] = plot\n",
    "            new_geodataframe = new_geodataframe.append(new_row)\n",
    "\n",
    "    assert len(new_geodataframe.index) == len(list(pd.core.common.flatten(\n",
    "        [\n",
    "            str(w).split(separator)\n",
    "            for w\n",
    "            in geodataframe[target_col]\n",
    "        ]))), 'splitting failed'\n",
    "\n",
    "    return new_geodataframe.reindex()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Split plots\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "outputs": [],
   "source": [
    "def quartic_kernel(u, bandwidth):\n",
    "    return np.where(\n",
    "            np.abs(u) <= bandwidth,\n",
    "            3 / (np.pi * bandwidth * bandwidth) * (1 - (u / bandwidth) ** 2) ** 2,\n",
    "            0\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% kernel function\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "outputs": [
    {
     "ename": "RasterioIOError",
     "evalue": "../data/processed/orthodox_density_1880_100_m.tif: No such file or directory",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mCPLE_OpenFailedError\u001B[0m                      Traceback (most recent call last)",
      "\u001B[1;32mrasterio\\_base.pyx\u001B[0m in \u001B[0;36mrasterio._base.DatasetBase.__init__\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;32mrasterio\\_shim.pyx\u001B[0m in \u001B[0;36mrasterio._shim.open_dataset\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;32mrasterio\\_err.pyx\u001B[0m in \u001B[0;36mrasterio._err.exc_wrap_pointer\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;31mCPLE_OpenFailedError\u001B[0m: ../data/processed/orthodox_density_1880_100_m.tif: No such file or directory",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[1;31mRasterioIOError\u001B[0m                           Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-218-e946c9ea7114>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     42\u001B[0m                 \u001B[0mkernel_function\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mquartic_kernel\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     43\u001B[0m             )\n\u001B[1;32m---> 44\u001B[1;33m             with rio.open(\n\u001B[0m\u001B[0;32m     45\u001B[0m                     \u001B[1;34mf\"../data/processed/{group}_density_{year}_{bw}_m.tif\"\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     46\u001B[0m                     \u001B[1;33m**\u001B[0m\u001B[0mraster_args\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\spatial_segregation\\lib\\site-packages\\rasterio\\env.py\u001B[0m in \u001B[0;36mwrapper\u001B[1;34m(*args, **kwds)\u001B[0m\n\u001B[0;32m    431\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    432\u001B[0m         \u001B[1;32mwith\u001B[0m \u001B[0menv_ctor\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0msession\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0msession\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 433\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mf\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    434\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    435\u001B[0m     \u001B[1;32mreturn\u001B[0m \u001B[0mwrapper\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\spatial_segregation\\lib\\site-packages\\rasterio\\__init__.py\u001B[0m in \u001B[0;36mopen\u001B[1;34m(fp, mode, driver, width, height, count, crs, transform, dtype, nodata, sharing, **kwargs)\u001B[0m\n\u001B[0;32m    216\u001B[0m         \u001B[1;31m# None.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    217\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mmode\u001B[0m \u001B[1;33m==\u001B[0m \u001B[1;34m'r'\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 218\u001B[1;33m             \u001B[0ms\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mDatasetReader\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mpath\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdriver\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mdriver\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0msharing\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0msharing\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    219\u001B[0m         \u001B[1;32melif\u001B[0m \u001B[0mmode\u001B[0m \u001B[1;33m==\u001B[0m \u001B[1;34m\"r+\"\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    220\u001B[0m             s = get_writer_for_path(path, driver=driver)(\n",
      "\u001B[1;32mrasterio\\_base.pyx\u001B[0m in \u001B[0;36mrasterio._base.DatasetBase.__init__\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;31mRasterioIOError\u001B[0m: ../data/processed/orthodox_density_1880_100_m.tif: No such file or directory"
     ]
    }
   ],
   "source": [
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "district_codes = pd.read_csv(data_dir / 'district_codes_1878.csv')\n",
    "district_codes = {k: v for k, v in district_codes.itertuples(index=False)}\n",
    "institutions = pd.read_csv(data_dir / 'institutions.csv', dtype={'district': str, 'plot_number': str})\n",
    "\n",
    "location_data = gpd.read_file(data_dir / 'raw' / 'plots_1878.shp').to_crs(epsg=3067)\n",
    "location_data = split_plots(location_data, target_col='NUMBER')\n",
    "location_data['district'] = [district_codes[int(d)] for d in location_data['DISTRICT']]\n",
    "location_data['plot_number'] = [str(i) for i in location_data['NUMBER']]\n",
    "location_data = location_data.set_index(['district', 'plot_number'])\n",
    "city = gpd.read_file(data_dir / 'raw' / 'city_1846.shp').to_crs(epsg=3067)\n",
    "location_data = location_data.loc[~location_data.geometry.within(city.geometry[0]).index.duplicated()]\n",
    "location_data = location_data.loc[location_data.geometry.within(city.geometry[0])]\n",
    "\n",
    "results = {}\n",
    "bws = 100, 150, 200, 250, 300, 400, 500\n",
    "\n",
    "for year in range(1880, 1921, 5):\n",
    "    s_ = []\n",
    "\n",
    "    for bw in bws:\n",
    "        population_data = pd.read_csv(\n",
    "            data_dir / 'interim' / f'pop_by_page_{year}.csv',\n",
    "            index_col=0,\n",
    "            dtype={'district': str, 'representative_plot': str, 'page_number': str},\n",
    "        ).pipe(prepare_pop_data)\n",
    "        population_data.rename({'representative_plot': 'plot_number'}, axis=1, inplace=True)\n",
    "        population_data = population_data.set_index(['district', 'plot_number'], drop=True)\n",
    "\n",
    "        population_data = population_data.pipe(remove_institutions, institutions, year)\n",
    "\n",
    "        page_location_data = location_data.join(population_data, on=['district', 'plot_number'])\n",
    "        page_location_data.dropna(axis=0, inplace=True)\n",
    "\n",
    "        for group in 'orthodox', 'lutheran', 'total':\n",
    "            density, raster_args = kernel_density_surface(\n",
    "                page_location_data,\n",
    "                group=group,\n",
    "                bandwidth=bw,\n",
    "                cell_size=25,\n",
    "                kernel_function=quartic_kernel,\n",
    "            )\n",
    "            with rio.open(\n",
    "                    f\"../data/processed/{group}_density_{year}_{bw}_m.tif\",\n",
    "                    **raster_args\n",
    "            ) as rfile:\n",
    "                rfile.write(density, 1)\n",
    "\n",
    "        S = get_S(\n",
    "            data=page_location_data,\n",
    "            bandwidth=bw,\n",
    "            cell_size=25,\n",
    "            kernel_function=quartic_kernel,\n",
    "        )\n",
    "\n",
    "        s_.append(S.statistic)\n",
    "\n",
    "    results[year] = s_\n",
    "\n",
    "results = pd.DataFrame.from_dict(\n",
    "    results,\n",
    "    orient='index',\n",
    "    columns=bws,\n",
    ")\n",
    "print(results)\n",
    "results.plot()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% main\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "districts_in_city = [\n",
    "    'Valli',\n",
    "    'Salakkalahti',\n",
    "    'Repola',\n",
    "    'Anina',\n",
    "    'Papula',\n",
    "    'P_Annan_kruunu',\n",
    "    'Hiekka',\n",
    "    'Pantsarlahti',\n",
    "    'Viipurin_esikaupunki',\n",
    "    'Paulovski',\n",
    "    'Havi',\n",
    "    'Saunalahti',\n",
    "    'Pietarin_esikaupunki',\n",
    "]\n",
    "\n",
    "results = {}\n",
    "\n",
    "for year in range(1880, 1921, 5):\n",
    "    population_data = pd.read_csv(\n",
    "            data_dir / 'interim' / f'pop_by_page_{year}.csv',\n",
    "            index_col=0,\n",
    "            dtype={'district': str, 'representative_plot': str, 'page_number': str},\n",
    "        ).pipe(prepare_pop_data)\n",
    "    population_data = population_data[population_data.district.isin(districts_in_city)]\n",
    "    population_data = population_data.loc[:, ['district', 'lutheran', 'orthodox', 'total']].groupby('district').sum()\n",
    "\n",
    "    D = Dissim(\n",
    "        population_data,\n",
    "        group_pop_var='orthodox',\n",
    "        total_pop_var='total',\n",
    "    )\n",
    "    results[year] = D.statistic\n",
    "\n",
    "    print(population_data)\n",
    "\n",
    "results = pd.Series(results)\n",
    "results.plot()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% aspatial segregation\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}